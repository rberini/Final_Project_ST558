---
title: "Diabetes Modeling"
author: "Robert Berini"
format: html
editor: visual
execute: 
  warning: false
  message: false
---

## Load required packages

```{r}
library(conflicted)
library(tidyverse)
library(tidymodels)
library(baguette)
library(vip)
library(future)
library(furrr)

conflicts_prefer(dplyr::lag)
conflicts_prefer(dplyr::filter)
tidymodels_prefer()

options(scipen = 999, digits = 2)
```

## Read data

```{r}
diabetes <- readRDS("data/diabetes.rds")
diabetes
```

## Split the data

Split the data into a training and test set (70/30 split). Use the `strata` argument to stratify the split on the `diabetes` outcome.

```{r}
set.seed(558)
diabetes_split <- initial_split(diabetes, prop = 0.7, strata = Diabetes)
diabetes_train <- training(diabetes_split)
diabetes_test <- testing(diabetes_split)
```

On the training set, create a 5 fold CV split.

```{r}
set.seed(558)
diabetes_5_fold <- vfold_cv(diabetes_train, v = 5, strata = Diabetes)
```

## Create recipe

placeholder text

```{r}
diabetes_rec <-
  recipe(Diabetes ~ ., data = diabetes_train) |>
  step_rm(CholCheck, Smoker, Stroke, PhysActivity:NoDocbcCost, DiffWalk, Education) #|>
  #step_normalize(all_numeric_predictors()) this step removed as not needed for trees
```

```{r}
diabetes_rec |>
  prep(training = diabetes_train) |>
  bake(diabetes_train)
```

Define event level and metrics set.

```{r}
metrics_set <- metric_set(mn_log_loss, roc_auc, accuracy, spec, sens)
```

Set up Classification Tree fit to use the `“rpart”` engine.

```{r}
tree_mod <- decision_tree(tree_depth = 8,
                          min_n = 25,
                          cost_complexity = tune()) |>
  set_engine("rpart") |>
  set_mode("classification")
```

Create workflow using recipe and model.

```{r}
diabetes_tree_wfl <- 
  workflow() |>
  add_recipe(diabetes_rec) |>
  add_model(tree_mod)
```

Create a tuning grid to consider varying levels of cost complexity.

```{r}
plan(multisession, workers = 4)

set.seed(558)

tree_fits <-
  diabetes_tree_wfl |> 
  tune_grid(resamples = diabetes_5_fold, grid = 20,
            metrics = metric_set(mn_log_loss))

plan(sequential)
```

Sort models by tuned cost complexity parameters with lowest Log Loss.

```{r}
tree_fits |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)
```

Identify parameter combination with lowest Log Loss.

```{r}
tree_best_params <-
  tree_fits |>
  select_best(metric = "mn_log_loss")
tree_best_params
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute metrics on the test set.

```{r}
diabetes_tree_final_fit <-
  diabetes_tree_wfl |>
  finalize_workflow(tree_best_params) |>
  last_fit(split = diabetes_split, metrics = metrics_set)

diabetes_tree_final_fit |>
  collect_metrics()
```

Visualize the classification tree.

```{r}
diabetes_tree_final_fit |>
  extract_workflow() |>
  extract_fit_engine() |>
  rpart.plot::rpart.plot(roundint = F, faclen = 2)
```

Produce a variable importance plot.

```{r}
diabetes_tree_final_model <- extract_fit_engine(diabetes_tree_final_fit) 
diabetes_tree_final_model |>
  vip(num_features = 15)
```

Generate a confusion matrix for final fit.

```{r}
tree_predictions <- 
  diabetes_tree_final_fit |>
  collect_predictions()

tree_conf_matrix <-conf_mat(tree_predictions, truth = Diabetes, estimate = .pred_class)
tree_conf_matrix
```

Collect and save final metrics for best Classification Tree model.

```{r}
tree_metrics <-
  diabetes_tree_final_fit |>
  collect_metrics()
tree_metrics
```

## Fit Random Forest Model

Set up Random Forest fit to use the `“ranger”` engine.

```{r}
rf_mod <- rand_forest(mtry = tune(),
                      min_n = 25,
                      trees = 500) |>
  set_engine("ranger", importance = "impurity") |>
  set_mode("classification")
```

Create workflow using recipe and model.

```{r}
diabetes_rf_wfl <- 
  workflow() |>
  add_recipe(diabetes_rec) |>
  add_model(rf_mod)
```

Create a tuning grid to consider varying levels of number of predictors that will be randomly sampled at each split and number of trees contained in the ensemble.

```{r}
plan(multisession, workers = 4)

set.seed(558)

rf_fits <-
  diabetes_rf_wfl |> 
  tune_grid(resamples = diabetes_5_fold, grid = 5,
            metrics = metric_set(mn_log_loss))

plan(sequential)
```

Sort models by tuned `mtry` parameter with lowest Log Loss.

```{r}
rf_fits |>
  collect_metrics() |>
  filter(.metric == "mn_log_loss") |>
  arrange(mean)
```

Identify parameter combination with lowest Log Loss.

```{r}

rf_best_params <-
  rf_fits |>
  select_best(metric = "mn_log_loss")
rf_best_params
```

Using the best model, fit the model to the entire training data set using the `last_fit()` function. Compute the Log Loss and Accuracy metrics on the test set.

```{r}

diabetes_rf_final_fit <-
  diabetes_rf_wfl |>
  finalize_workflow(rf_best_params) |>
  last_fit(split = diabetes_split, metrics = metrics_set)

diabetes_rf_final_fit |>
  collect_metrics()
```

Produce a variable importance plot.

```{r}

diabetes_rf_final_model <- extract_fit_engine(diabetes_rf_final_fit) 
diabetes_rf_final_model |>
  vip(num_features = 15)
```

Generate a confusion matrix for final fit.

```{r}
rf_predictions <- 
  diabetes_tree_final_fit |>
  collect_predictions()

rf_conf_matrix <-conf_mat(rf_predictions, truth = Diabetes, estimate = .pred_class)
rf_conf_matrix
```

Collect and save final metrics for best Random Forest model.

```{r}

rf_metrics <-
  diabetes_rf_final_fit |>
  collect_metrics()
rf_metrics
```

## Select the Best Model

Compare all final models using both Log Loss and ROC AUC.

```{r}

rbind(tree_metrics, rf_metrics) |>
  filter(.metric == "mn_log_loss") |>
  mutate(model = c("Classification Tree", "Random Forest")) |>
  select(model, "mean_mn_log_loss" = .estimate)
```

```{r}

rbind(tree_metrics, rf_metrics) |>
  filter(.metric == "roc_auc") |>
  mutate(model = c("Classification Tree", "Random Forest")) |>
  select(model, "mean_roc_auc" = .estimate)
```

The Random Forest model performs slightly better on both metrics so that will serve as our final model.

Save best model.

```{r}
save(diabetes_rf_final_model, file = "model/diabetes_rf_final_model.RData")
save(diabetes_rf_final_fit, file = "model/diabetes_rf_final_fit.RData")
```
