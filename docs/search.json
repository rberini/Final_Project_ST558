[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Diabetes Modeling",
    "section": "",
    "text": "library(conflicted)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(baguette)\nlibrary(vip)\nlibrary(future)\nlibrary(furrr)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\ntidymodels_prefer()\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "Modeling.html#load-required-packages",
    "href": "Modeling.html#load-required-packages",
    "title": "Diabetes Modeling",
    "section": "",
    "text": "library(conflicted)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(baguette)\nlibrary(vip)\nlibrary(future)\nlibrary(furrr)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\ntidymodels_prefer()\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "Modeling.html#read-data",
    "href": "Modeling.html#read-data",
    "title": "Diabetes Modeling",
    "section": "Read data",
    "text": "Read data\n\ndiabetes &lt;- readRDS(\"data/diabetes.rds\")\ndiabetes\n\n# A tibble: 253,680 × 22\n   Diabetes HighBP HighChol CholCheck   BMI Smoker Stroke HeartDiseaseorAttack\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;               \n 1 No       Yes    Yes      Yes          40 Yes    No     No                  \n 2 No       No     No       No           25 Yes    No     No                  \n 3 No       Yes    Yes      Yes          28 No     No     No                  \n 4 No       Yes    No       Yes          27 No     No     No                  \n 5 No       Yes    Yes      Yes          24 No     No     No                  \n 6 No       Yes    Yes      Yes          25 Yes    No     No                  \n 7 No       Yes    No       Yes          30 Yes    No     No                  \n 8 No       Yes    Yes      Yes          25 Yes    No     No                  \n 9 Yes      Yes    Yes      Yes          30 Yes    No     Yes                 \n10 No       No     No       Yes          24 No     No     No                  \n# ℹ 253,670 more rows\n# ℹ 14 more variables: PhysActivity &lt;fct&gt;, Fruits &lt;fct&gt;, Veggies &lt;fct&gt;,\n#   HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;, NoDocbcCost &lt;fct&gt;,\n#   GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;, DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;,\n#   Age &lt;ord&gt;, Education &lt;ord&gt;, Income &lt;ord&gt;"
  },
  {
    "objectID": "Modeling.html#split-the-data",
    "href": "Modeling.html#split-the-data",
    "title": "Diabetes Modeling",
    "section": "Split the data",
    "text": "Split the data\nSplit the data into a training and test set (70/30 split). Use the strata argument to stratify the split on the diabetes outcome.\n\nset.seed(558)\ndiabetes_split &lt;- initial_split(diabetes, prop = 0.7, strata = \"Diabetes\")\ndiabetes_train &lt;- training(diabetes_split)\ndiabetes_test &lt;- testing(diabetes_split)\n\nOn the training set, create a 5 fold CV split.\n\ndiabetes_5_fold &lt;- vfold_cv(diabetes_train, 5)"
  },
  {
    "objectID": "Modeling.html#create-recipe",
    "href": "Modeling.html#create-recipe",
    "title": "Diabetes Modeling",
    "section": "Create recipe",
    "text": "Create recipe\nplaceholder text\n\ndiabetes_rec &lt;-\n  recipe(Diabetes ~ ., data = diabetes_train) |&gt;\n  step_rm(CholCheck, Smoker, Stroke, Fruits:NoDocbcCost) #|&gt;\n  #step_normalize(all_numeric_predictors()) |&gt;\n  #step_pca(ends_with(\"Hlth\"), num_comp = 3, prefix = \"Hlth\")\n\n\ndiabetes_rec |&gt;\n  prep(training = diabetes_train) |&gt;\n  bake(diabetes_train)\n\n# A tibble: 177,575 × 14\n   HighBP HighChol   BMI HeartDiseaseorAttack PhysActivity GenHlth MentHlth\n   &lt;fct&gt;  &lt;fct&gt;    &lt;dbl&gt; &lt;fct&gt;                &lt;fct&gt;          &lt;dbl&gt;    &lt;dbl&gt;\n 1 No     No          25 No                   Yes                3        0\n 2 Yes    Yes         28 No                   No                 5       30\n 3 Yes    No          27 No                   Yes                2        0\n 4 Yes    No          30 No                   No                 3        0\n 5 Yes    Yes         25 No                   Yes                3        0\n 6 No     No          24 No                   No                 2        0\n 7 No     Yes         33 No                   Yes                4       30\n 8 Yes    No          33 No                   Yes                2        5\n 9 Yes    Yes         21 No                   Yes                3        0\n10 Yes    Yes         38 No                   No                 5       15\n# ℹ 177,565 more rows\n# ℹ 7 more variables: PhysHlth &lt;dbl&gt;, DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;,\n#   Education &lt;ord&gt;, Income &lt;ord&gt;, Diabetes &lt;fct&gt;\n\n\nDefine event level and metrics set.\n\nmetrics_set &lt;- metric_set(mn_log_loss, roc_auc, accuracy, spec, sens)\n\nSet up Classification Tree fit to use the “rpart” engine.\n\ntree_mod &lt;- decision_tree(tree_depth = 8,\n                          min_n = 25,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nCreate workflow using recipe and model.\n\ndiabetes_tree_wfl &lt;- \n  workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(tree_mod)\n\nCreate a tuning grid to consider varying levels of cost complexity.\n\nplan(multisession, workers = 4)\n\nset.seed(558)\n\ntree_fits &lt;-\n  diabetes_tree_wfl |&gt; \n  tune_grid(resamples = diabetes_5_fold, grid = 20,\n            metrics = metric_set(mn_log_loss))\n\nplan(sequential)\n\nSort models by tuned cost complexity parameters with lowest Log Loss.\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 20 × 7\n   cost_complexity .metric     .estimator  mean     n std_err .config           \n             &lt;dbl&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;             \n 1        2.95e- 7 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 2        8.91e- 8 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 3        5.29e- 6 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 4        3.70e- 8 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 5        5.70e- 7 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 6        4.43e- 9 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 7        1.11e- 9 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 8        1.16e- 8 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n 9        4.31e-10 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n10        2.08e- 6 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n11        2.28e-10 mn_log_loss binary     0.331     5 0.00117 Preprocessor1_Mod…\n12        1.99e- 5 mn_log_loss binary     0.331     5 0.00113 Preprocessor1_Mod…\n13        6.48e- 5 mn_log_loss binary     0.337     5 0.00336 Preprocessor1_Mod…\n14        1.90e- 4 mn_log_loss binary     0.353     5 0.00263 Preprocessor1_Mod…\n15        3.81e- 4 mn_log_loss binary     0.355     5 0.00202 Preprocessor1_Mod…\n16        6.66e- 4 mn_log_loss binary     0.355     5 0.00211 Preprocessor1_Mod…\n17        3.63e- 3 mn_log_loss binary     0.355     5 0.00205 Preprocessor1_Mod…\n18        5.86e- 3 mn_log_loss binary     0.365     5 0.0107  Preprocessor1_Mod…\n19        8.90e- 2 mn_log_loss binary     0.404     5 0.00147 Preprocessor1_Mod…\n20        2.84e- 2 mn_log_loss binary     0.404     5 0.00147 Preprocessor1_Mod…\n\n\nIdentify parameter combination with lowest Log Loss.\n\ntree_best_params &lt;-\n  tree_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\ntree_best_params\n\n# A tibble: 1 × 2\n  cost_complexity .config              \n            &lt;dbl&gt; &lt;chr&gt;                \n1     0.000000295 Preprocessor1_Model03\n\n\nUsing the best model, fit the model to the entire training data set using the last_fit() function. Compute metrics on the test set.\n\ndiabetes_tree_final_fit &lt;-\n  diabetes_tree_wfl |&gt;\n  finalize_workflow(tree_best_params) |&gt;\n  last_fit(split = diabetes_split, metrics = metrics_set)\n\ndiabetes_tree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 spec        binary         0.981 Preprocessor1_Model1\n3 sens        binary         0.137 Preprocessor1_Model1\n4 mn_log_loss binary         0.329 Preprocessor1_Model1\n5 roc_auc     binary         0.801 Preprocessor1_Model1\n\n\nVisualize the classification tree.\n\ndiabetes_tree_final_fit |&gt;\n  extract_workflow() |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = F, faclen = 2)\n\n\n\n\n\n\n\n\nProduce a variable importance plot.\n\ndiabetes_tree_final_model &lt;- extract_fit_engine(diabetes_tree_final_fit) \ndiabetes_tree_final_model |&gt;\n  vip(num_features = 15)\n\n\n\n\n\n\n\n\nGenerate a confusion matrix for final fit.\n\ntree_predictions &lt;- \n  diabetes_tree_final_fit |&gt;\n  collect_predictions()\n\ntree_conf_matrix &lt;-conf_mat(tree_predictions, truth = Diabetes, estimate = .pred_class)\ntree_conf_matrix\n\n          Truth\nPrediction   Yes    No\n       Yes  1453  1213\n       No   9151 64288\n\n\nCollect final metrics for best Classification Tree model.\n\ntree_metrics &lt;-\n  diabetes_tree_final_fit |&gt;\n  collect_metrics()\ntree_metrics\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 spec        binary         0.981 Preprocessor1_Model1\n3 sens        binary         0.137 Preprocessor1_Model1\n4 mn_log_loss binary         0.329 Preprocessor1_Model1\n5 roc_auc     binary         0.801 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#fit-random-forest-model",
    "href": "Modeling.html#fit-random-forest-model",
    "title": "Diabetes Modeling",
    "section": "Fit Random Forest Model",
    "text": "Fit Random Forest Model\nSet up Random Forest fit to use the “ranger” engine.\n\nrf_mod &lt;- rand_forest(mtry = tune(),\n                      min_n = 25,\n                      trees = 500) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\nCreate workflow using recipe 1.\n\ndiabetes_rf_wfl &lt;- \n  workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(rf_mod)\n\nCreate a tuning grid to consider varying levels of number of predictors that will be randomly sampled at each split and number of trees contained in the ensemble.\n\nplan(multisession, workers = 4)\n\nset.seed(558)\n\nrf_fits &lt;-\n  diabetes_rf_wfl |&gt; \n  tune_grid(resamples = diabetes_5_fold, grid = 5,\n            metrics = metric_set(mn_log_loss))\n\nplan(sequential)\n\nSort models by tuned parameters with lowest Log Loss.\n\nrf_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 5 × 7\n   mtry .metric     .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     3 mn_log_loss binary     0.318     5 0.00155 Preprocessor1_Model2\n2     5 mn_log_loss binary     0.323     5 0.00172 Preprocessor1_Model5\n3     8 mn_log_loss binary     0.332     5 0.00144 Preprocessor1_Model1\n4    10 mn_log_loss binary     0.337     5 0.00229 Preprocessor1_Model3\n5    12 mn_log_loss binary     0.340     5 0.00228 Preprocessor1_Model4\n\n\nIdentify parameter combination with lowest Log Loss.\n\nrf_best_params &lt;-\n  rf_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\nrf_best_params\n\n# A tibble: 1 × 2\n   mtry .config             \n  &lt;int&gt; &lt;chr&gt;               \n1     3 Preprocessor1_Model2\n\n\nUsing the best model, fit the model to the entire training data set using the last_fit() function. Compute the Log Loss and Accuracy metrics on the test set.\n\ndiabetes_rf_final_fit &lt;-\n  diabetes_rf_wfl |&gt;\n  finalize_workflow(rf_best_params) |&gt;\n  last_fit(split = diabetes_split, metrics = metrics_set)\n\ndiabetes_rf_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.865 Preprocessor1_Model1\n2 spec        binary         0.985 Preprocessor1_Model1\n3 sens        binary         0.129 Preprocessor1_Model1\n4 mn_log_loss binary         0.317 Preprocessor1_Model1\n5 roc_auc     binary         0.822 Preprocessor1_Model1\n\n\nProduce a variable importance plot.\n\ndiabetes_rf_final_model &lt;- extract_fit_engine(diabetes_rf_final_fit) \ndiabetes_rf_final_model |&gt;\n  vip(num_features = 15)\n\n\n\n\n\n\n\n\nGenerate a confusion matrix for final fit.\n\nrf_predictions &lt;- \n  diabetes_tree_final_fit |&gt;\n  collect_predictions()\n\nrf_conf_matrix &lt;-conf_mat(rf_predictions, truth = Diabetes, estimate = .pred_class)\nrf_conf_matrix\n\n          Truth\nPrediction   Yes    No\n       Yes  1453  1213\n       No   9151 64288\n\n\nCollect final Log Loss and Accuracy metrics for best Random Forest model.\n\nrf_metrics &lt;-\n  diabetes_rf_final_fit |&gt;\n  collect_metrics()\nrf_metrics\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.865 Preprocessor1_Model1\n2 spec        binary         0.985 Preprocessor1_Model1\n3 sens        binary         0.129 Preprocessor1_Model1\n4 mn_log_loss binary         0.317 Preprocessor1_Model1\n5 roc_auc     binary         0.822 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#select-the-best-model",
    "href": "Modeling.html#select-the-best-model",
    "title": "Diabetes Modeling",
    "section": "Select the Best Model",
    "text": "Select the Best Model\nCompare all final models using both Log Loss and ROC AUC\n\nrbind(tree_metrics, rf_metrics) |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  mutate(model = c(\"Classification Tree\", \"Random Forest\")) |&gt;\n  select(model, \"mean_mn_log_loss\" = .estimate)\n\n# A tibble: 2 × 2\n  model               mean_mn_log_loss\n  &lt;chr&gt;                          &lt;dbl&gt;\n1 Classification Tree            0.329\n2 Random Forest                  0.317\n\n\n\nrbind(tree_metrics, rf_metrics) |&gt;\n  filter(.metric == \"roc_auc\") |&gt;\n  mutate(model = c(\"Classification Tree\", \"Random Forest\")) |&gt;\n  select(model, \"mean_roc_auc\" = .estimate)\n\n# A tibble: 2 × 2\n  model               mean_roc_auc\n  &lt;chr&gt;                      &lt;dbl&gt;\n1 Classification Tree        0.801\n2 Random Forest              0.822"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Diabetes EDA",
    "section": "",
    "text": "library(conflicted)\nlibrary(skimr)\nlibrary(psych)\nlibrary(tidyverse)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "EDA.html#load-required-packages",
    "href": "EDA.html#load-required-packages",
    "title": "Diabetes EDA",
    "section": "",
    "text": "library(conflicted)\nlibrary(skimr)\nlibrary(psych)\nlibrary(tidyverse)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "EDA.html#read-data",
    "href": "EDA.html#read-data",
    "title": "Diabetes EDA",
    "section": "Read data",
    "text": "Read data\n\ndiabetes_raw &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")"
  },
  {
    "objectID": "EDA.html#check-and-manipulate-the-data",
    "href": "EDA.html#check-and-manipulate-the-data",
    "title": "Diabetes EDA",
    "section": "Check and manipulate the data",
    "text": "Check and manipulate the data\nExplore columns names, column types, and values.\n\nglimpse(diabetes_raw)\n\nRows: 253,680\nColumns: 22\n$ Diabetes_binary      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0…\n$ HighBP               &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1…\n$ HighChol             &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1…\n$ CholCheck            &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0…\n$ Stroke               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ HeartDiseaseorAttack &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PhysActivity         &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1…\n$ Fruits               &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1…\n$ Veggies              &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1…\n$ HvyAlcoholConsump    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AnyHealthcare        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ NoDocbcCost          &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ GenHlth              &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2, 3…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0…\n$ Sex                  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ Age                  &lt;dbl&gt; 9, 7, 9, 11, 11, 10, 9, 11, 9, 8, 13, 10, 7, 11, …\n$ Education            &lt;dbl&gt; 4, 6, 4, 3, 5, 6, 6, 4, 5, 4, 6, 5, 5, 4, 6, 6, 4…\n$ Income               &lt;dbl&gt; 3, 1, 8, 6, 4, 8, 7, 4, 1, 3, 8, 1, 7, 6, 2, 8, 3…\n\n\nCheck for any missing values.\n\ndiabetes_raw |&gt;\n  skim() |&gt;\n  focus(n_missing, complete_rate, numeric.hist)\n\n\nData summary\n\n\nName\ndiabetes_raw\n\n\nNumber of rows\n253680\n\n\nNumber of columns\n22\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n22\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nhist\n\n\n\n\nDiabetes_binary\n0\n1\n▇▁▁▁▁\n\n\nHighBP\n0\n1\n▇▁▁▁▆\n\n\nHighChol\n0\n1\n▇▁▁▁▆\n\n\nCholCheck\n0\n1\n▁▁▁▁▇\n\n\nBMI\n0\n1\n▇▅▁▁▁\n\n\nSmoker\n0\n1\n▇▁▁▁▆\n\n\nStroke\n0\n1\n▇▁▁▁▁\n\n\nHeartDiseaseorAttack\n0\n1\n▇▁▁▁▁\n\n\nPhysActivity\n0\n1\n▂▁▁▁▇\n\n\nFruits\n0\n1\n▅▁▁▁▇\n\n\nVeggies\n0\n1\n▂▁▁▁▇\n\n\nHvyAlcoholConsump\n0\n1\n▇▁▁▁▁\n\n\nAnyHealthcare\n0\n1\n▁▁▁▁▇\n\n\nNoDocbcCost\n0\n1\n▇▁▁▁▁\n\n\nGenHlth\n0\n1\n▅▇▇▃▁\n\n\nMentHlth\n0\n1\n▇▁▁▁▁\n\n\nPhysHlth\n0\n1\n▇▁▁▁▁\n\n\nDiffWalk\n0\n1\n▇▁▁▁▂\n\n\nSex\n0\n1\n▇▁▁▁▆\n\n\nAge\n0\n1\n▂▃▇▇▆\n\n\nEducation\n0\n1\n▁▁▅▅▇\n\n\nIncome\n0\n1\n▁▁▃▂▇\n\n\n\n\n\nReassign column types\n\n#consistent with social science practices, treating GenHlth Likert scale as an interval scale\ntrue_numeric_cols &lt;- c(\"BMI\", \"GenHlth\", \"MentHlth\", \"PhysHlth\")\nmulti_fac_cols &lt;- c(\"Age\", \"Education\", \"Income\")\n\n\ndiabetes &lt;-\n  diabetes_raw |&gt;\n  rename(Diabetes = Diabetes_binary) |&gt;\n  mutate(Sex = factor(Sex, levels = 0:1, labels = c(\"Female\", \"Male\"))) |&gt;\n  mutate(across(\n    .cols = !c(Sex, all_of(true_numeric_cols), all_of(multi_fac_cols)),\n    .fns = ~ factor(.x, levels = 0:1, labels = c(\"No\", \"Yes\"))\n  )) |&gt;\n  mutate(across(where(is.factor), fct_rev))\n\n\ndiabetes &lt;-\n  diabetes |&gt;\n  mutate(Age = factor(Age, \n                      levels = 1:13, \n                      labels = c(\"Age 18 - 24\", \"Age 25 to 29\", \"Age 30 to 34\", \n                                 \"Age 35 to 39\", \"Age 40 to 44\", \"Age 45 to 49\", \n                                 \"Age 50 to 54\", \"Age 55 to 59\", \"Age 60 to 64\", \n                                 \"Age 65 to 69\", \"Age 70 to 74\", \"Age 75 to 79\", \n                                 \"Age 80 or older\"),\n                      ordered = T)) |&gt;\n  mutate(Education = factor(Education, \n                            levels = 1:6, \n                            labels = c(\"No school or only kindergarten\", \n                                       \"Elementary\", \n                                       \"Some high school\", \n                                       \"High school graduate\", \n                                       \"Some college or technical school\", \n                                       \"College graduate\"),\n                            ordered = T)) |&gt;\n  mutate(Income = factor(Income, \n                         levels = 1:8, \n                         labels = c(\"Less than $10,000\", \n                                    \"$10,000 to less than $15,000\", \n                                    \"$15,000 to less than $20,000\", \n                                    \"$20,000 to less than $25,000\", \n                                    \"$25,000 to less than $35,000\", \n                                    \"$35,000 to less than $50,000\", \n                                    \"$50,000 to less than $75,000\", \n                                    \"$75,000 or more\"),\n                         ordered = T))\n\n\nglimpse(diabetes)\n\nRows: 253,680\nColumns: 22\n$ Diabetes             &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, Yes, No,…\n$ HighBP               &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, N…\n$ HighChol             &lt;fct&gt; Yes, No, Yes, No, Yes, Yes, No, Yes, Yes, No, No,…\n$ CholCheck            &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, …\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;fct&gt; Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, No, Yes…\n$ Stroke               &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, N…\n$ HeartDiseaseorAttack &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, No, No, …\n$ PhysActivity         &lt;fct&gt; No, Yes, No, Yes, Yes, Yes, No, Yes, No, No, Yes,…\n$ Fruits               &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, No, No, Yes, No, Yes,…\n$ Veggies              &lt;fct&gt; Yes, No, No, Yes, Yes, Yes, No, Yes, Yes, Yes, Ye…\n$ HvyAlcoholConsump    &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, N…\n$ AnyHealthcare        &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, …\n$ NoDocbcCost          &lt;fct&gt; No, Yes, Yes, No, No, No, No, No, No, No, No, No,…\n$ GenHlth              &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2, 3…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;fct&gt; Yes, No, Yes, No, No, No, No, Yes, Yes, No, No, Y…\n$ Sex                  &lt;fct&gt; Female, Female, Female, Female, Female, Male, Fem…\n$ Age                  &lt;ord&gt; Age 60 to 64, Age 50 to 54, Age 60 to 64, Age 70 …\n$ Education            &lt;ord&gt; High school graduate, College graduate, High scho…\n$ Income               &lt;ord&gt; \"$15,000 to less than $20,000\", \"Less than $10,00…\n\n\nGenerate basic summary statistics for numeric columns and check the unique values for the categorical variables.\n\ndiabetes |&gt;\n  select(where(is.numeric)) |&gt;\n  describe()\n\n         vars      n mean  sd median trimmed mad min max range skew kurtosis\nBMI         1 253680 28.4 6.6     27    27.7 4.5  12  98    86 2.12    11.00\nGenHlth     2 253680  2.5 1.1      2     2.5 1.5   1   5     4 0.42    -0.38\nMentHlth    3 253680  3.2 7.4      0     1.0 0.0   0  30    30 2.72     6.44\nPhysHlth    4 253680  4.2 8.7      0     1.8 0.0   0  30    30 2.21     3.50\n           se\nBMI      0.01\nGenHlth  0.00\nMentHlth 0.01\nPhysHlth 0.02\n\n\n\ndiabetes |&gt;\n  select(where(is.factor)) |&gt;\n  summary(maxsum = Inf)\n\n Diabetes     HighBP       HighChol     CholCheck    Smoker       Stroke      \n Yes: 35346   Yes:108829   Yes:107591   Yes:244210   Yes:112423   Yes: 10292  \n No :218334   No :144851   No :146089   No :  9470   No :141257   No :243388  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n HeartDiseaseorAttack PhysActivity Fruits       Veggies      HvyAlcoholConsump\n Yes: 23893           Yes:191920   Yes:160898   Yes:205841   Yes: 14256       \n No :229787           No : 61760   No : 92782   No : 47839   No :239424       \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n AnyHealthcare NoDocbcCost  DiffWalk         Sex        \n Yes:241263    Yes: 21354   Yes: 42675   Male  :111706  \n No : 12417    No :232326   No :211005   Female:141974  \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n              Age                                   Education     \n Age 18 - 24    : 5700   No school or only kindergarten  :   174  \n Age 25 to 29   : 7598   Elementary                      :  4043  \n Age 30 to 34   :11123   Some high school                :  9478  \n Age 35 to 39   :13823   High school graduate            : 62750  \n Age 40 to 44   :16157   Some college or technical school: 69910  \n Age 45 to 49   :19819   College graduate                :107325  \n Age 50 to 54   :26314                                            \n Age 55 to 59   :30832                                            \n Age 60 to 64   :33244                                            \n Age 65 to 69   :32194                                            \n Age 70 to 74   :23533                                            \n Age 75 to 79   :15980                                            \n Age 80 or older:17363                                            \n                          Income     \n Less than $10,000           : 9811  \n $10,000 to less than $15,000:11783  \n $15,000 to less than $20,000:15994  \n $20,000 to less than $25,000:20135  \n $25,000 to less than $35,000:25883  \n $35,000 to less than $50,000:36470  \n $50,000 to less than $75,000:43219  \n $75,000 or more             :90385  \n                                     \n                                     \n                                     \n                                     \n                                     \n\n\nSave manipulated data set\n\nsaveRDS(diabetes, \"data/diabetes.rds\")"
  },
  {
    "objectID": "EDA.html#eda",
    "href": "EDA.html#eda",
    "title": "Diabetes EDA",
    "section": "EDA",
    "text": "EDA\n\ndiabetes |&gt;\n  select(dplyr::ends_with(\"Hlth\")) |&gt;\n  cor()\n\n         GenHlth MentHlth PhysHlth\nGenHlth     1.00     0.30     0.52\nMentHlth    0.30     1.00     0.35\nPhysHlth    0.52     0.35     1.00"
  }
]