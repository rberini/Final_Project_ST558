[
  {
    "objectID": "Modeling.html",
    "href": "Modeling.html",
    "title": "Diabetes Modeling",
    "section": "",
    "text": "library(conflicted)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(baguette)\nlibrary(vip)\nlibrary(future)\nlibrary(furrr)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\ntidymodels_prefer()\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "Modeling.html#load-required-packages",
    "href": "Modeling.html#load-required-packages",
    "title": "Diabetes Modeling",
    "section": "",
    "text": "library(conflicted)\nlibrary(tidyverse)\nlibrary(tidymodels)\nlibrary(baguette)\nlibrary(vip)\nlibrary(future)\nlibrary(furrr)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\ntidymodels_prefer()\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "Modeling.html#read-data",
    "href": "Modeling.html#read-data",
    "title": "Diabetes Modeling",
    "section": "Read data",
    "text": "Read data\n\ndiabetes &lt;- readRDS(\"data/diabetes.rds\")\ndiabetes\n\n# A tibble: 253,680 × 22\n   Diabetes HighBP HighChol CholCheck   BMI Smoker Stroke HeartDiseaseorAttack\n   &lt;fct&gt;    &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;     &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;               \n 1 No       Yes    Yes      Yes          40 Yes    No     No                  \n 2 No       No     No       No           25 Yes    No     No                  \n 3 No       Yes    Yes      Yes          28 No     No     No                  \n 4 No       Yes    No       Yes          27 No     No     No                  \n 5 No       Yes    Yes      Yes          24 No     No     No                  \n 6 No       Yes    Yes      Yes          25 Yes    No     No                  \n 7 No       Yes    No       Yes          30 Yes    No     No                  \n 8 No       Yes    Yes      Yes          25 Yes    No     No                  \n 9 Yes      Yes    Yes      Yes          30 Yes    No     Yes                 \n10 No       No     No       Yes          24 No     No     No                  \n# ℹ 253,670 more rows\n# ℹ 14 more variables: PhysActivity &lt;fct&gt;, Fruits &lt;fct&gt;, Veggies &lt;fct&gt;,\n#   HvyAlcoholConsump &lt;fct&gt;, AnyHealthcare &lt;fct&gt;, NoDocbcCost &lt;fct&gt;,\n#   GenHlth &lt;dbl&gt;, MentHlth &lt;dbl&gt;, PhysHlth &lt;dbl&gt;, DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;,\n#   Age &lt;ord&gt;, Education &lt;ord&gt;, Income &lt;ord&gt;"
  },
  {
    "objectID": "Modeling.html#split-the-data",
    "href": "Modeling.html#split-the-data",
    "title": "Diabetes Modeling",
    "section": "Split the data",
    "text": "Split the data\nSplit the data into a training and test set (70/30 split). Use the strata argument to stratify the split on the diabetes outcome.\n\nset.seed(558)\ndiabetes_split &lt;- initial_split(diabetes, prop = 0.7, strata = \"Diabetes\")\ndiabetes_train &lt;- training(diabetes_split)\ndiabetes_test &lt;- testing(diabetes_split)\n\nOn the training set, create a 5 fold CV split.\n\ndiabetes_5_fold &lt;- vfold_cv(diabetes_train, 5)"
  },
  {
    "objectID": "Modeling.html#create-recipe",
    "href": "Modeling.html#create-recipe",
    "title": "Diabetes Modeling",
    "section": "Create recipe",
    "text": "Create recipe\nplaceholder text\n\ndiabetes_rec &lt;-\n  recipe(Diabetes ~ ., data = diabetes_train) |&gt;\n  step_rm(Fruits:NoDocbcCost) |&gt;\n  step_normalize(all_numeric_predictors()) |&gt;\n  step_pca(ends_with(\"Hlth\"), num_comp = 1, prefix = \"Hlth\")\n\n\ndiabetes_rec |&gt;\n  prep(training = diabetes_train) |&gt;\n  bake(diabetes_train)\n\n# A tibble: 177,575 × 15\n   HighBP HighChol CholCheck     BMI Smoker Stroke HeartDiseaseorAttack\n   &lt;fct&gt;  &lt;fct&gt;    &lt;fct&gt;       &lt;dbl&gt; &lt;fct&gt;  &lt;fct&gt;  &lt;fct&gt;               \n 1 No     No       No        -0.514  Yes    No     No                  \n 2 Yes    Yes      Yes       -0.0570 No     No     No                  \n 3 Yes    No       Yes       -0.209  No     No     No                  \n 4 Yes    No       Yes        0.247  Yes    No     No                  \n 5 Yes    Yes      Yes       -0.514  Yes    No     No                  \n 6 No     No       Yes       -0.666  No     No     No                  \n 7 No     Yes      Yes        0.704  Yes    Yes    No                  \n 8 Yes    No       Yes        0.704  No     No     No                  \n 9 Yes    Yes      Yes       -1.12   No     No     No                  \n10 Yes    Yes      Yes        1.47   Yes    No     No                  \n# ℹ 177,565 more rows\n# ℹ 8 more variables: PhysActivity &lt;fct&gt;, DiffWalk &lt;fct&gt;, Sex &lt;fct&gt;, Age &lt;ord&gt;,\n#   Education &lt;ord&gt;, Income &lt;ord&gt;, Diabetes &lt;fct&gt;, Hlth1 &lt;dbl&gt;\n\n\nDefine metrics set.\n\nmetrics_set &lt;- metric_set(mn_log_loss, roc_auc, accuracy, spec, sens)\n\nSet up Classification Tree fit to use the “rpart” engine.\n\ntree_mod &lt;- decision_tree(tree_depth = tune(),\n                          min_n = 10,\n                          cost_complexity = tune()) |&gt;\n  set_engine(\"rpart\") |&gt;\n  set_mode(\"classification\")\n\nCreate workflow using recipe and model.\n\ndiabetes_tree_wfl &lt;- \n  workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(tree_mod)\n\nCreate a tuning grid to consider varying levels of tree depth and cost complexity.\n\nplan(multisession, workers = 4)\n\nset.seed(558)\n\ntree_fits &lt;-\n  diabetes_tree_wfl |&gt; \n  tune_grid(resamples = diabetes_5_fold, grid = 20,\n            metrics = metric_set(mn_log_loss))\n\nplan(sequential)\n\nSort models by tuned tree depth and cost complexity parameters with lowest Log Loss.\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 20 × 8\n   cost_complexity tree_depth .metric     .estimator  mean     n std_err .config\n             &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;  \n 1        2.05e- 9          8 mn_log_loss binary     0.334     5 0.00146 Prepro…\n 2        3.42e- 9          9 mn_log_loss binary     0.334     5 0.00109 Prepro…\n 3        2.70e- 7         10 mn_log_loss binary     0.346     5 0.00234 Prepro…\n 4        8.51e- 6         10 mn_log_loss binary     0.346     5 0.00220 Prepro…\n 5        4.50e- 4          7 mn_log_loss binary     0.352     5 0.00138 Prepro…\n 6        9.99e- 4          9 mn_log_loss binary     0.352     5 0.00132 Prepro…\n 7        1.12e- 7          6 mn_log_loss binary     0.352     5 0.00124 Prepro…\n 8        2.27e- 3          5 mn_log_loss binary     0.352     5 0.00128 Prepro…\n 9        9.99e- 7         11 mn_log_loss binary     0.366     5 0.00206 Prepro…\n10        4.65e- 5         12 mn_log_loss binary     0.378     5 0.00111 Prepro…\n11        2.03e- 5         12 mn_log_loss binary     0.394     5 0.00495 Prepro…\n12        9.32e- 3         14 mn_log_loss binary     0.404     5 0.00147 Prepro…\n13        1.88e- 6          2 mn_log_loss binary     0.404     5 0.00147 Prepro…\n14        4.20e- 2          6 mn_log_loss binary     0.404     5 0.00147 Prepro…\n15        1.40e- 4          2 mn_log_loss binary     0.404     5 0.00147 Prepro…\n16        1.76e- 2          4 mn_log_loss binary     0.404     5 0.00147 Prepro…\n17        2.33e- 8          4 mn_log_loss binary     0.404     5 0.00147 Prepro…\n18        1.84e-10          3 mn_log_loss binary     0.404     5 0.00147 Prepro…\n19        1.44e- 8         14 mn_log_loss binary     0.525     5 0.00920 Prepro…\n20        5.87e-10         14 mn_log_loss binary     0.525     5 0.00920 Prepro…\n\n\nShow model performance at different levels of tree depth and cost complexity parameters.\n\ntree_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  mutate(tree_depth = factor(tree_depth)) %&gt;%\n  ggplot(aes(cost_complexity, mean, color = tree_depth)) +\n  geom_line(size = 1.5, alpha = 0.6) +\n  geom_point(size = 2) +\n  scale_x_log10(labels = scales::label_number()) +\n  scale_color_viridis_d()\n\n\n\n\n\n\n\n\nIdentify parameter combination with lowest Log Loss.\n\ntree_best_params &lt;-\n  tree_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\ntree_best_params\n\n# A tibble: 1 × 3\n  cost_complexity tree_depth .config              \n            &lt;dbl&gt;      &lt;int&gt; &lt;chr&gt;                \n1   0.00000000205          8 Preprocessor1_Model10\n\n\nUsing the best model, fit the model to the entire training data set using the last_fit() function. Compute metrics on the test set.\n\ndiabetes_tree_final_fit &lt;-\n  diabetes_tree_wfl |&gt;\n  finalize_workflow(tree_best_params) |&gt;\n  last_fit(split = diabetes_split, metrics = metrics_set)\n\ndiabetes_tree_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.862 Preprocessor1_Model1\n2 spec        binary         0.148 Preprocessor1_Model1\n3 sens        binary         0.978 Preprocessor1_Model1\n4 mn_log_loss binary         0.335 Preprocessor1_Model1\n5 roc_auc     binary         0.788 Preprocessor1_Model1\n\n\nVisualize the classification tree.\n\ndiabetes_tree_final_fit |&gt;\n  extract_workflow() |&gt;\n  extract_fit_engine() |&gt;\n  rpart.plot::rpart.plot(roundint = F, faclen = 2)\n\n\n\n\n\n\n\n\nCollect final metrics for best Classification Tree model.\n\ntree_metrics &lt;-\n  diabetes_tree_final_fit |&gt;\n  collect_metrics()\ntree_metrics\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.862 Preprocessor1_Model1\n2 spec        binary         0.148 Preprocessor1_Model1\n3 sens        binary         0.978 Preprocessor1_Model1\n4 mn_log_loss binary         0.335 Preprocessor1_Model1\n5 roc_auc     binary         0.788 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#fit-random-forest-model",
    "href": "Modeling.html#fit-random-forest-model",
    "title": "Diabetes Modeling",
    "section": "Fit Random Forest Model",
    "text": "Fit Random Forest Model\nSet up Random Forest fit to use the “ranger” engine.\n\nrf_mod &lt;- rand_forest(mtry = tune(),\n                      min_n = tune(),\n                      trees = 500) |&gt;\n  set_engine(\"ranger\", importance = \"impurity\") |&gt;\n  set_mode(\"classification\")\n\nCreate workflow using recipe 1.\n\ndiabetes_rf_wfl &lt;- \n  workflow() |&gt;\n  add_recipe(diabetes_rec) |&gt;\n  add_model(rf_mod)\n\nCreate a tuning grid to consider varying levels of number of predictors that will be randomly sampled at each split and number of trees contained in the ensemble.\n\nplan(multisession, workers = 4)\n\nset.seed(558)\n\nrf_fits &lt;-\n  diabetes_rf_wfl |&gt; \n  tune_grid(resamples = diabetes_5_fold, grid = 5,\n            metrics = metric_set(mn_log_loss))\n\nplan(sequential)\n\nSort models by tuned parameters with lowest Log Loss.\n\nrf_fits |&gt;\n  collect_metrics() |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  arrange(mean)\n\n# A tibble: 5 × 8\n   mtry min_n .metric     .estimator  mean     n std_err .config             \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;       &lt;chr&gt;      &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt; &lt;chr&gt;               \n1     3     3 mn_log_loss binary     0.321     5 0.00164 Preprocessor1_Model3\n2     5    22 mn_log_loss binary     0.325     5 0.00168 Preprocessor1_Model4\n3    11    38 mn_log_loss binary     0.331     5 0.00167 Preprocessor1_Model1\n4     7    17 mn_log_loss binary     0.333     5 0.00126 Preprocessor1_Model5\n5    13    27 mn_log_loss binary     0.338     5 0.00203 Preprocessor1_Model2\n\n\nIdentify parameter combination with lowest Log Loss.\n\nrf_best_params &lt;-\n  rf_fits |&gt;\n  select_best(metric = \"mn_log_loss\")\nrf_best_params\n\n# A tibble: 1 × 3\n   mtry min_n .config             \n  &lt;int&gt; &lt;int&gt; &lt;chr&gt;               \n1     3     3 Preprocessor1_Model3\n\n\nUsing the best model, fit the model to the entire training data set using the last_fit() function. Compute the Log Loss and Accuracy metrics on the test set.\n\ndiabetes_rf_final_fit &lt;-\n  diabetes_rf_wfl |&gt;\n  finalize_workflow(rf_best_params) |&gt;\n  last_fit(split = diabetes_split, metrics = metrics_set)\n\ndiabetes_rf_final_fit |&gt;\n  collect_metrics()\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 spec        binary         0.126 Preprocessor1_Model1\n3 sens        binary         0.983 Preprocessor1_Model1\n4 mn_log_loss binary         0.321 Preprocessor1_Model1\n5 roc_auc     binary         0.817 Preprocessor1_Model1\n\n\nProduce a variable importance plot.\n\ndiabetes_rf_final_model &lt;- extract_fit_engine(diabetes_rf_final_fit) \ndiabetes_rf_final_model |&gt;\n  vip(num_features = 22)\n\n\n\n\n\n\n\n\nCollect final Log Loss and Accuracy metrics for best Random Forest model.\n\nrf_metrics &lt;-\n  diabetes_rf_final_fit |&gt;\n  collect_metrics()\nrf_metrics\n\n# A tibble: 5 × 4\n  .metric     .estimator .estimate .config             \n  &lt;chr&gt;       &lt;chr&gt;          &lt;dbl&gt; &lt;chr&gt;               \n1 accuracy    binary         0.864 Preprocessor1_Model1\n2 spec        binary         0.126 Preprocessor1_Model1\n3 sens        binary         0.983 Preprocessor1_Model1\n4 mn_log_loss binary         0.321 Preprocessor1_Model1\n5 roc_auc     binary         0.817 Preprocessor1_Model1"
  },
  {
    "objectID": "Modeling.html#select-the-best-model",
    "href": "Modeling.html#select-the-best-model",
    "title": "Diabetes Modeling",
    "section": "Select the Best Model",
    "text": "Select the Best Model\nCompare all final models using both Log Loss and ROC AUC\n\nrbind(tree_metrics, rf_metrics) |&gt;\n  filter(.metric == \"mn_log_loss\") |&gt;\n  mutate(model = c(\"Classification Tree\", \"Random Forest\")) |&gt;\n  select(model, \"mean_mn_log_loss\" = .estimate)\n\n# A tibble: 2 × 2\n  model               mean_mn_log_loss\n  &lt;chr&gt;                          &lt;dbl&gt;\n1 Classification Tree            0.335\n2 Random Forest                  0.321\n\n\n\nrbind(tree_metrics, rf_metrics) |&gt;\n  filter(.metric == \"roc_auc\") |&gt;\n  mutate(model = c(\"Classification Tree\", \"Random Forest\")) |&gt;\n  select(model, \"mean_roc_auc\" = .estimate)\n\n# A tibble: 2 × 2\n  model               mean_roc_auc\n  &lt;chr&gt;                      &lt;dbl&gt;\n1 Classification Tree        0.788\n2 Random Forest              0.817"
  },
  {
    "objectID": "EDA.html",
    "href": "EDA.html",
    "title": "Diabetes EDA",
    "section": "",
    "text": "library(conflicted)\nlibrary(skimr)\nlibrary(psych)\nlibrary(tidyverse)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "EDA.html#load-required-packages",
    "href": "EDA.html#load-required-packages",
    "title": "Diabetes EDA",
    "section": "",
    "text": "library(conflicted)\nlibrary(skimr)\nlibrary(psych)\nlibrary(tidyverse)\n\nconflicts_prefer(dplyr::lag)\nconflicts_prefer(dplyr::filter)\n\noptions(scipen = 999, digits = 2)"
  },
  {
    "objectID": "EDA.html#read-data",
    "href": "EDA.html#read-data",
    "title": "Diabetes EDA",
    "section": "Read data",
    "text": "Read data\n\ndiabetes_raw &lt;- read_csv(\"data/diabetes_binary_health_indicators_BRFSS2015.csv\")"
  },
  {
    "objectID": "EDA.html#check-and-manipulate-the-data",
    "href": "EDA.html#check-and-manipulate-the-data",
    "title": "Diabetes EDA",
    "section": "Check and manipulate the data",
    "text": "Check and manipulate the data\nExplore columns names, column types, and values.\n\nglimpse(diabetes_raw)\n\nRows: 253,680\nColumns: 22\n$ Diabetes_binary      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0…\n$ HighBP               &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1…\n$ HighChol             &lt;dbl&gt; 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1…\n$ CholCheck            &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;dbl&gt; 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0…\n$ Stroke               &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ HeartDiseaseorAttack &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0…\n$ PhysActivity         &lt;dbl&gt; 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1…\n$ Fruits               &lt;dbl&gt; 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1…\n$ Veggies              &lt;dbl&gt; 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1…\n$ HvyAlcoholConsump    &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0…\n$ AnyHealthcare        &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ NoDocbcCost          &lt;dbl&gt; 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0…\n$ GenHlth              &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2, 3…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0…\n$ Sex                  &lt;dbl&gt; 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0…\n$ Age                  &lt;dbl&gt; 9, 7, 9, 11, 11, 10, 9, 11, 9, 8, 13, 10, 7, 11, …\n$ Education            &lt;dbl&gt; 4, 6, 4, 3, 5, 6, 6, 4, 5, 4, 6, 5, 5, 4, 6, 6, 4…\n$ Income               &lt;dbl&gt; 3, 1, 8, 6, 4, 8, 7, 4, 1, 3, 8, 1, 7, 6, 2, 8, 3…\n\n\nCheck for any missing values.\n\ndiabetes_raw |&gt;\n  skim() |&gt;\n  focus(n_missing, complete_rate, numeric.hist)\n\n\nData summary\n\n\nName\ndiabetes_raw\n\n\nNumber of rows\n253680\n\n\nNumber of columns\n22\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nnumeric\n22\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: numeric\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nhist\n\n\n\n\nDiabetes_binary\n0\n1\n▇▁▁▁▁\n\n\nHighBP\n0\n1\n▇▁▁▁▆\n\n\nHighChol\n0\n1\n▇▁▁▁▆\n\n\nCholCheck\n0\n1\n▁▁▁▁▇\n\n\nBMI\n0\n1\n▇▅▁▁▁\n\n\nSmoker\n0\n1\n▇▁▁▁▆\n\n\nStroke\n0\n1\n▇▁▁▁▁\n\n\nHeartDiseaseorAttack\n0\n1\n▇▁▁▁▁\n\n\nPhysActivity\n0\n1\n▂▁▁▁▇\n\n\nFruits\n0\n1\n▅▁▁▁▇\n\n\nVeggies\n0\n1\n▂▁▁▁▇\n\n\nHvyAlcoholConsump\n0\n1\n▇▁▁▁▁\n\n\nAnyHealthcare\n0\n1\n▁▁▁▁▇\n\n\nNoDocbcCost\n0\n1\n▇▁▁▁▁\n\n\nGenHlth\n0\n1\n▅▇▇▃▁\n\n\nMentHlth\n0\n1\n▇▁▁▁▁\n\n\nPhysHlth\n0\n1\n▇▁▁▁▁\n\n\nDiffWalk\n0\n1\n▇▁▁▁▂\n\n\nSex\n0\n1\n▇▁▁▁▆\n\n\nAge\n0\n1\n▂▃▇▇▆\n\n\nEducation\n0\n1\n▁▁▅▅▇\n\n\nIncome\n0\n1\n▁▁▃▂▇\n\n\n\n\n\nReassign column types\n\n#consistent with social science practices, treating GenHlth Likert scale as an interval scale\ntrue_numeric_cols &lt;- c(\"BMI\", \"GenHlth\", \"MentHlth\", \"PhysHlth\")\nmulti_fac_cols &lt;- c(\"Age\", \"Education\", \"Income\")\n\n\ndiabetes &lt;-\n  diabetes_raw |&gt;\n  rename(Diabetes = Diabetes_binary) |&gt;\n  mutate(Age = factor(Age, \n                      levels = 1:13, \n                      labels = c(\"Age 18 - 24\", \"Age 25 to 29\", \"Age 30 to 34\", \n                                 \"Age 35 to 39\", \"Age 40 to 44\", \"Age 45 to 49\", \n                                 \"Age 50 to 54\", \"Age 55 to 59\", \"Age 60 to 64\", \n                                 \"Age 65 to 69\", \"Age 70 to 74\", \"Age 75 to 79\", \n                                 \"Age 80 or older\"),\n                      ordered = T)) |&gt;\n  mutate(Education = factor(Education, \n                            levels = 1:6, \n                            labels = c(\"No school or only kindergarten\", \n                                       \"Elementary\", \n                                       \"Some high school\", \n                                       \"High school graduate\", \n                                       \"Some college or technical school\", \n                                       \"College graduate\"),\n                            ordered = T)) |&gt;\n  mutate(Income = factor(Income, \n                         levels = 1:8, \n                         labels = c(\"Less than $10,000\", \n                                    \"$10,000 to less than $15,000\", \n                                    \"$15,000 to less than $20,000\", \n                                    \"$20,000 to less than $25,000\", \n                                    \"$25,000 to less than $35,000\", \n                                    \"$35,000 to less than $50,000\", \n                                    \"$50,000 to less than $75,000\", \n                                    \"$75,000 or more\"),\n                         ordered = T))|&gt;\n  mutate(Sex = factor(as.numeric(Sex), levels = c(0, 1), labels = c(\"Female\", \"Male\"))) |&gt;\n  mutate(across(\n    .cols = !c(Sex, true_numeric_cols, multi_fac_cols),\n    .fns = ~ factor(as.numeric(.x), levels = c(0, 1), labels = c(\"No\", \"Yes\"))\n  ))\n\n\nglimpse(diabetes)\n\nRows: 253,680\nColumns: 22\n$ Diabetes             &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, Yes, No,…\n$ HighBP               &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, No, N…\n$ HighChol             &lt;fct&gt; Yes, No, Yes, No, Yes, Yes, No, Yes, Yes, No, No,…\n$ CholCheck            &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, …\n$ BMI                  &lt;dbl&gt; 40, 25, 28, 27, 24, 25, 30, 25, 30, 24, 25, 34, 2…\n$ Smoker               &lt;fct&gt; Yes, Yes, No, No, No, Yes, Yes, Yes, Yes, No, Yes…\n$ Stroke               &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, N…\n$ HeartDiseaseorAttack &lt;fct&gt; No, No, No, No, No, No, No, No, Yes, No, No, No, …\n$ PhysActivity         &lt;fct&gt; No, Yes, No, Yes, Yes, Yes, No, Yes, No, No, Yes,…\n$ Fruits               &lt;fct&gt; No, No, Yes, Yes, Yes, Yes, No, No, Yes, No, Yes,…\n$ Veggies              &lt;fct&gt; Yes, No, No, Yes, Yes, Yes, No, Yes, Yes, Yes, Ye…\n$ HvyAlcoholConsump    &lt;fct&gt; No, No, No, No, No, No, No, No, No, No, No, No, N…\n$ AnyHealthcare        &lt;fct&gt; Yes, No, Yes, Yes, Yes, Yes, Yes, Yes, Yes, Yes, …\n$ NoDocbcCost          &lt;fct&gt; No, Yes, Yes, No, No, No, No, No, No, No, No, No,…\n$ GenHlth              &lt;dbl&gt; 5, 3, 5, 2, 2, 2, 3, 3, 5, 2, 3, 3, 3, 4, 4, 2, 3…\n$ MentHlth             &lt;dbl&gt; 18, 0, 30, 0, 3, 0, 0, 0, 30, 0, 0, 0, 0, 0, 30, …\n$ PhysHlth             &lt;dbl&gt; 15, 0, 30, 0, 0, 2, 14, 0, 30, 0, 0, 30, 15, 0, 2…\n$ DiffWalk             &lt;fct&gt; Yes, No, Yes, No, No, No, No, Yes, Yes, No, No, Y…\n$ Sex                  &lt;fct&gt; Female, Female, Female, Female, Female, Male, Fem…\n$ Age                  &lt;ord&gt; Age 60 to 64, Age 50 to 54, Age 60 to 64, Age 70 …\n$ Education            &lt;ord&gt; High school graduate, College graduate, High scho…\n$ Income               &lt;ord&gt; \"$15,000 to less than $20,000\", \"Less than $10,00…\n\n\nGenerate basic summary statistics for numeric columns and check the unique values for the categorical variables.\n\ndiabetes |&gt;\n  select(where(is.numeric)) |&gt;\n  describe()\n\n         vars      n mean  sd median trimmed mad min max range skew kurtosis\nBMI         1 253680 28.4 6.6     27    27.7 4.5  12  98    86 2.12    11.00\nGenHlth     2 253680  2.5 1.1      2     2.5 1.5   1   5     4 0.42    -0.38\nMentHlth    3 253680  3.2 7.4      0     1.0 0.0   0  30    30 2.72     6.44\nPhysHlth    4 253680  4.2 8.7      0     1.8 0.0   0  30    30 2.21     3.50\n           se\nBMI      0.01\nGenHlth  0.00\nMentHlth 0.01\nPhysHlth 0.02\n\n\n\ndiabetes |&gt;\n  select(where(is.factor)) |&gt;\n  summary(maxsum = Inf)\n\n Diabetes     HighBP       HighChol     CholCheck    Smoker       Stroke      \n No :218334   No :144851   No :146089   No :  9470   No :141257   No :243388  \n Yes: 35346   Yes:108829   Yes:107591   Yes:244210   Yes:112423   Yes: 10292  \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n HeartDiseaseorAttack PhysActivity Fruits       Veggies      HvyAlcoholConsump\n No :229787           No : 61760   No : 92782   No : 47839   No :239424       \n Yes: 23893           Yes:191920   Yes:160898   Yes:205841   Yes: 14256       \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n                                                                              \n AnyHealthcare NoDocbcCost  DiffWalk         Sex        \n No : 12417    No :232326   No :211005   Female:141974  \n Yes:241263    Yes: 21354   Yes: 42675   Male  :111706  \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n                                                        \n              Age                                   Education     \n Age 18 - 24    : 5700   No school or only kindergarten  :   174  \n Age 25 to 29   : 7598   Elementary                      :  4043  \n Age 30 to 34   :11123   Some high school                :  9478  \n Age 35 to 39   :13823   High school graduate            : 62750  \n Age 40 to 44   :16157   Some college or technical school: 69910  \n Age 45 to 49   :19819   College graduate                :107325  \n Age 50 to 54   :26314                                            \n Age 55 to 59   :30832                                            \n Age 60 to 64   :33244                                            \n Age 65 to 69   :32194                                            \n Age 70 to 74   :23533                                            \n Age 75 to 79   :15980                                            \n Age 80 or older:17363                                            \n                          Income     \n Less than $10,000           : 9811  \n $10,000 to less than $15,000:11783  \n $15,000 to less than $20,000:15994  \n $20,000 to less than $25,000:20135  \n $25,000 to less than $35,000:25883  \n $35,000 to less than $50,000:36470  \n $50,000 to less than $75,000:43219  \n $75,000 or more             :90385  \n                                     \n                                     \n                                     \n                                     \n                                     \n\n\nSave manipulated data set\n\nsaveRDS(diabetes, \"data/diabetes.rds\")"
  },
  {
    "objectID": "EDA.html#eda",
    "href": "EDA.html#eda",
    "title": "Diabetes EDA",
    "section": "EDA",
    "text": "EDA"
  }
]